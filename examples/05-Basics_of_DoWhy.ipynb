{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced1317d",
   "metadata": {},
   "source": [
    "# causalgraph (cg) with Tigramite and DoWhy\n",
    "\n",
    "This tutorial describes an example of learning a causal graph with ```Tigramite```, exporting it to ```cg```\n",
    "and then doing causal inference with ```DoWhy```.\n",
    "\n",
    "\n",
    "> ```DoWhy``` is a Python library that aims to spark causal thinking and analysis. DoWhy provides a principled four-step interface for causal inference that focuses on explicitly modeling causal assumptions and validating them as much as possible. The key feature of DoWhy is its state-of-the-art refutation API that can automatically test causal assumptions for any estimation method, thus making inference more robust and accessible to non-experts. DoWhy supports estimation of the average causal effect for ```backdoor```, ```frontdoor```, ```instrumental variable``` and other identification methods, and estimation of the conditional effect (```CATE```) through an integration with the EconML library. \n",
    "> ([Source - https://microsoft.github.io/dowhy/](https://microsoft.github.io/dowhy/); there you can find more detailed information about DoWhy as well.)\n",
    "\n",
    "\n",
    "\n",
    "NOTE: This notebook is not intended to provide an extensive overview of the features of DoWhy but rather to show how to start working with DoWhy when you have a cg graph.\n",
    "\n",
    "Required packages to run this tutorial are:\n",
    "- dowhy==0.7.1\n",
    "- tigramite==4.2.2.1\n",
    "- pandas==1.2.3'\n",
    "- causalgraph (cg)\n",
    "- jupyter (to run this notebook)\n",
    "- [owlready2 0.35](https://owlready2.readthedocs.io/en/v0.35/) (backend for causalgraph store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ad9f8",
   "metadata": {},
   "source": [
    "Initially, import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "# general imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# dowhy imports\n",
    "from dowhy import CausalModel\n",
    "# tigramite imports\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite import plotting as tp\n",
    "from tigramite import data_processing as pp\n",
    "from tigramite.independence_tests import ParCorr\n",
    "# causalgraph imports\n",
    "from causalgraph import Graph\n",
    "from causalgraph.utils import mapping\n",
    "from causalgraph.utils.path_utils import get_project_root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e09bece",
   "metadata": {},
   "source": [
    "## Tigramite\n",
    "\n",
    "Use the built-in Tigramite function ```var_process``` to create time series data with linear dependencies.  \n",
    "In the given example, the values of time series 0 and time series 1 are computed in the following way:  \n",
    "```timeseries0(t) = 3 * timeseries1(t-4) + noise```  \n",
    "```timeseries1(t) = 2 * timeseries2(t-3) + 0.6 * timeseries4(t-1) + noise```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time series data\n",
    "np.random.seed(41)\n",
    "T = 3000 # time series length\n",
    "links_coeffs = {0: [((1, -4), 3)                    ],\n",
    "                1: [((2, -3), 2), ((4, -1), 0.6)    ],\n",
    "                2: [                                ],\n",
    "                3: [((1, -2), 0.7)                  ],\n",
    "                4: [                                ],\n",
    "                5: [((1, -2), 0.7)                  ]}\n",
    "data, _ = pp.var_process(links_coeffs, T=T)\n",
    "plt.plot(data[:200,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f467e6a7",
   "metadata": {},
   "source": [
    "Create a Tigramite dataframe and assign names to the time series. Furthermore, initialize ```ParCorr``` which is an independence test suited to detect linear dependencies. ParCorr is used in the algorithm ```PCMCI``` which is initialized as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc44a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dataframe and variable names\n",
    "var_names = ['bumpy_feeling', 'flat_tire', 'thorns_on_road', 'noise', 'glass_on_road', 'steering_problems']\n",
    "dataframe = pp.DataFrame(data, datatime = np.arange(len(data)), var_names=var_names)\n",
    "# init independence test and algorithm\n",
    "parcorr = ParCorr(significance='analytic', confidence='analytic')\n",
    "pcmci = PCMCI(dataframe=dataframe, cond_ind_test=parcorr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e850b4c",
   "metadata": {},
   "source": [
    "Run PCMCI and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run algorithm\n",
    "results = pcmci.run_pcmci(tau_max=8, pc_alpha=None)\n",
    "q_matrix = pcmci.get_corrected_pvalues(p_matrix=results['p_matrix'], fdr_method='fdr_bh')\n",
    "results['q_matrix'] = q_matrix\n",
    "# get links and plot graph\n",
    "link_matrix = pcmci.return_significant_links(pq_matrix=q_matrix,\n",
    "              val_matrix=results['val_matrix'], alpha_level=0.01)['link_matrix']\n",
    "tp.plot_graph(val_matrix=results['val_matrix'], link_matrix=link_matrix,\n",
    "              var_names=var_names,link_colorbar_label='cross-MCI',\n",
    "              node_colorbar_label='auto-MCI', figsize=(12, 7)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3c6e3",
   "metadata": {},
   "source": [
    "When the tigramite results are exported to cg, there needs to be a name for each edge encoded in a dictionary.  \n",
    "This dictionary is created here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35111d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of edges\n",
    "edge_names = {}\n",
    "d1, d2, d3 = np.nonzero(link_matrix)\n",
    "inds = [(d1[i], d2[i], d3[i]) for i in range(np.sum(link_matrix))]\n",
    "for i in range(len(inds)):\n",
    "    cause = inds[i][0]\n",
    "    effect = inds[i][1]\n",
    "    edge_names['Edge_'+str(i)] = { 'cause': var_names[cause],\n",
    "                                   'effect': var_names[effect]}\n",
    "print(json.dumps(edge_names, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2677d8",
   "metadata": {},
   "source": [
    "## causalgraph (cg)\n",
    "The results of the Tigramite analysis are now imported in a cg graph.  \n",
    "Therefore, a new cg graph is initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cef0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate graph\n",
    "sql_file_name = 'dowhy_example.sqlite3'\n",
    "if os.path.exists(sql_file_name):\n",
    "    os.remove(sql_file_name)\n",
    "    print(f\"Deleted old db with name {sql_file_name}\")\n",
    "G = Graph(sql_db_filename=sql_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90960148",
   "metadata": {},
   "source": [
    "Converting a causal graph from Tigramite to the cg format is done by using a dictionary that describes the causal graph.  \n",
    "This dictionary is created from the Tigramite results. The dictionary contains all the properties describing the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0358ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert tigramite result in dictionary\n",
    "graph_dict = G.readwrite.tigra.read(var_names, edge_names, link_matrix, q_matrix, 1)\n",
    "print(json.dumps(graph_dict, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77798dd7",
   "metadata": {},
   "source": [
    "The cg graph is updated with the information in the dictionary.  \n",
    "Then, it is exported to ```.gml``` since this file format is used by DoWhy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09495221",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping.update_graph_from_dict(G.store, graph_dict)\n",
    "# export graph to gml\n",
    "G.readwrite.nx.export_gml('./gml_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d415b7d8",
   "metadata": {},
   "source": [
    "## DoWhy\n",
    "DoWhy takes a graph and data as input. The graph already exists as a gml file. It encodes our assumptions about the dependencies of the variables.  \n",
    "The data exists as well but only as time series data. [DoWhy does not support timeseries data directly](https://github.com/microsoft/dowhy/issues/174). Since Tigramite detected the time lag between the variables, the time series are shifted in such a way that the causal dependencies all take place at the same time step.  \n",
    "Then, a pandas dataframe is created from the shifted time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee075614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the data by the timelag\n",
    "for i in range(1, len(data)):\n",
    "    data[1000-i, 1] = data[1000-i-4, 1]\n",
    "    data[1000-i, 2] = data[1000-i-7, 2]\n",
    "    data[1000-i, 3] = data[1000-i-2, 3]\n",
    "    data[1000-i, 4] = data[1000-i-5, 4]\n",
    "    data[1000-i, 5] = data[1000-i-2, 5]\n",
    "for i in range(10):\n",
    "    data = np.delete(data, (0), axis=0)\n",
    "df = pd.DataFrame(data, columns=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea2a7f",
   "metadata": {},
   "source": [
    "Doing ```Causal Inference``` with DoWhy usually involves four steps which are explained in the following sections.\\\n",
    "NOTE: The descriptions of the steps are taken directly from the [official documentation](https://microsoft.github.io/dowhy/#).\n",
    "\n",
    "```1. Model a causal problem```\n",
    "\n",
    "DoWhy creates an underlying causal graphical model for each problem. This serves to make each causal assumption explicit. Currently, DoWhy supports two formats for graph input: gml (preferred) and dot. We strongly suggest to use gml as the input format, as it works well with networkx. You can provide the graph either as a .gml file or as a string. If you prefer to use dot format, you will need to install additional packages (pydot or pygraphviz, see the installation section above). Both .dot files and string format are supported. While not recommended, you can also specify common causes and/or instruments directly instead of providing a graph. ([Source](https://microsoft.github.io/dowhy/#i-model-a-causal-problem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8e0c9",
   "metadata": {},
   "source": [
    "The gml graph is imported. Then, a causal model is created by using the ```CausalModel``` function of DoWhy. We specify the graph, the data and the dependency that should be examined. In this case, we want to know the effect of ```thorns_on_road``` on ```bumpy_feeling```.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e237641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read graph from gml create causal model with dowhy\n",
    "graph_str = open('./gml_graph.gml', 'r').read()\n",
    "model = CausalModel(data=df, treatment=['thorns_on_road'],\n",
    "                    outcome=['bumpy_feeling'], graph=graph_str)\n",
    "# show model\n",
    "model.view_model()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9131604e",
   "metadata": {},
   "source": [
    "```2. Identify a target estimand under the model.```\n",
    "\n",
    "Based on the causal graph, DoWhy finds all possible ways of identifying a desired causal effect based on the graphical model. It uses graph-based criteria and do-calculus to find expressions that can identify the causal effect. Supported identification criteria are ```Back-door criterion```, ```Front-door criterion```, ```Instrumental Variables```, ```Mediation``` (Direct and indirect effect identification) ([Source](https://microsoft.github.io/dowhy/#ii-identify-a-target-estimand-under-the-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af72b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identification\n",
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb3dc6",
   "metadata": {},
   "source": [
    "```3. Estimate causal effect based on the identified estimand```\n",
    "\n",
    "DoWhy supports methods based on both back-door criterion and instrumental variables. It also provides a non-parametric confidence intervals and a permutation test for testing the statistical significance of obtained estimate. ([Source](https://microsoft.github.io/dowhy/#iii-estimate-causal-effect-based-on-the-identified-estimand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaabe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimation\n",
    "causal_estimate = model.estimate_effect(identified_estimand,\n",
    "                                        method_name=\"backdoor.linear_regression\")\n",
    "print(causal_estimate)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7d543",
   "metadata": {},
   "source": [
    "```4. Refute the obtained estimate```\n",
    "\n",
    "Having access to multiple refutation methods to validate an effect estimate from a causal estimator is a key benefit of using DoWhy. ([Source](https://microsoft.github.io/dowhy/#iv-refute-the-obtained-estimate))\\\n",
    "NOTE: Not shown here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d19ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
